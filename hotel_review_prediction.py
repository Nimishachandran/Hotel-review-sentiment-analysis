# -*- coding: utf-8 -*-
"""HOTEL REVIEW PREDICTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ULojOsXDl8RXOgB3rzs_eoJuVHYcsqQR
"""

import numpy as np
import pandas as pd
import nltk

a=pd.read_csv('train.csv.zip')
b=pd.read_csv('test.csv.zip')

a

a=a.iloc[15000:30000]

a.head()

a.tail()

#DATA CLEANING/ EDA

a.info()

a.isnull().sum()

# Commented out IPython magic to ensure Python compatibility.
### Checking for the Distribution of Default ###
import matplotlib.pyplot as plt
# %matplotlib inline
print('Percentage for default\n')
print(round(a.Is_Response.value_counts(normalize=True)*100,2))
round(a.Is_Response.value_counts(normalize=True)*100,2).plot(kind='bar')
plt.title('Percentage Distributions by review type')
plt.show()

a.drop(columns = ['User_ID', 'Browser_Used', 'Device_Used'], inplace = True)

a.head()

#CHANGING TO LOWERCASE

a['Description']=a['Description']. apply(str. lower)

a['cleaned_description'] = pd.DataFrame(a['Description'])

a.head()

a.replace('[^\w\s]')

a['cleaned_description1'] = pd.DataFrame(a['cleaned_description'])

a.head()

a['Description'] = a['Description'].str.replace(r'\[|\]', '')

a['cleaned_description_new'] = pd.DataFrame(a['cleaned_description1'])

a.head()

from sklearn.model_selection import train_test_split

Independent_var = a.cleaned_description_new
Dependent_var = a.Is_Response

IV_train, IV_test, DV_train, DV_test = train_test_split(Independent_var, Dependent_var, test_size = 0.1, random_state = 225)

print('IV_train :', len(IV_train))
print('IV_test  :', len(IV_test))
print('DV_train :', len(DV_train))
print('DV_test  :', len(DV_test))

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression

tvec = TfidfVectorizer()
clf2 = LogisticRegression(solver = "lbfgs")


from sklearn.pipeline import Pipeline

model = Pipeline([('vectorizer',tvec),('classifier',clf2)])

model.fit(IV_train, DV_train)


from sklearn.metrics import confusion_matrix

predictions = model.predict(IV_test)

confusion_matrix(predictions, DV_test)

import seaborn as sns
print(f"Confusion Matrix: \n{confusion_matrix(DV_test,predictions)}")
sns.heatmap(confusion_matrix(DV_test,predictions), annot=True, cmap="Blues",fmt=".0f")

from sklearn.metrics import accuracy_score, precision_score, recall_score

print("Accuracy : ", accuracy_score(predictions, DV_test))
print("Precision : ", precision_score(predictions, DV_test, average = 'weighted'))
print("Recall : ", recall_score(predictions, DV_test, average = 'weighted'))



from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report

df = pd.read_csv('train.csv.zip')

# Separate independent and dependent variables
X = df['Description'].astype(str)  # Assuming 'text_column' is where your text data is stored
y = df['Is_Response'].astype(str)  # Assuming 'sentiment_column' is where your labels are stored

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=48)

vectorizer = TfidfVectorizer(max_features=10000)  # You can adjust max_features as needed
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

svm_classifier = SVC(kernel='linear')  # Linear kernel works well for text data
svm_classifier.fit(X_train_vec, y_train)

y_pred1 = svm_classifier.predict(X_test_vec)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred1)
print(f'Accuracy: {accuracy}')

# Optionally, print classification report for more detailed evaluation
print(classification_report(y_test, y_pred1))
print('Accuracy:',accuracy)

import seaborn as sns
print(f"Confusion Matrix: \n{confusion_matrix(y_test,y_pred1)}")
sns.heatmap(confusion_matrix(y_test,y_pred1), annot=True, cmap="Blues",fmt=".0f")

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, classification_report

df = pd.read_csv('train.csv.zip')

# Separate independent and dependent variables
X = df['Description'].astype(str)  # Assuming 'text_column' is where your text data is stored
y = df['Is_Response'].astype(str)  # Assuming 'sentiment_column' is where your labels are stored

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

vectorizer = TfidfVectorizer(max_features=10000)  # You can adjust max_features as needed
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

k = 8 # Choose the number of neighbors (k) for KNN
knn_classifier = KNeighborsClassifier(n_neighbors=k)
knn_classifier.fit(X_train_vec, y_train)

y_pred2 = knn_classifier.predict(X_test_vec)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred2)
print(f'Accuracy: {accuracy}')

# Optionally, print classification report for more detailed evaluation
print(classification_report(y_test, y_pred2))

import seaborn as sns
print(f"Confusion Matrix: \n{confusion_matrix(y_test,y_pred2)}")
sns.heatmap(confusion_matrix(y_test,y_pred2), annot=True, cmap="Blues",fmt=".0f")

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report

# Load your dataset (replace 'data.csv' with your actual file path)
df = pd.read_csv('train.csv.zip')
# Separate independent and dependent variables
X = df['Description'].astype(str)  # Assuming 'text_column' is where your text data is stored
y = df['Is_Response'].astype(str)  # Assuming 'sentiment_column' is where your labels are stored

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize the text data using CountVectorizer
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train the Naive Bayes model
nb_classifier = MultinomialNB()
nb_classifier.fit(X_train_vec, y_train)

# Make predictions on the test set
y_pred3= nb_classifier.predict(X_test_vec)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred3)
print(f'Accuracy: {accuracy}')

# Optionally, print classification report for more detailed evaluation
print(classification_report(y_test, y_pred3))

import seaborn as sns
print(f"Confusion Matrix: \n{confusion_matrix(y_test,y_pred3)}")
sns.heatmap(confusion_matrix(y_test,y_pred3), annot=True, cmap="Blues",fmt=".0f")

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load your dataset (replace 'data.csv' with your actual file path)
df = pd.read_csv('train.csv.zip')

# Separate independent and dependent variables
X = df['Description'].astype(str)  # Assuming 'text_column' is where your text data is stored
y = df['Is_Response'].astype(str)  # Assuming 'sentiment_column' is where your labels are stored

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Vectorize the text data using TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=10000)  # You can adjust max_features as needed
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Train the Random Forest model
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)
rf_classifier.fit(X_train_vec, y_train)

# Make predictions on the test set
y_pred4 = rf_classifier.predict(X_test_vec)

# Evaluate accuracy
accuracy = accuracy_score(y_test, y_pred4)
print(f'Accuracy: {accuracy}')

# Optionally, print classification report for more detailed evaluation
print(classification_report(y_test, y_pred4))

import seaborn as sns
print(f"Confusion Matrix: \n{confusion_matrix(y_test,y_pred4)}")
sns.heatmap(confusion_matrix(y_test,y_pred4), annot=True, cmap="Blues",fmt=".0f")